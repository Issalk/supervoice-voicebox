{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97f69095-f2ce-4966-9544-04964e19eaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base\n",
    "import itertools\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import textgrid\n",
    "import random\n",
    "\n",
    "# ML\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DistributedSampler, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Local\n",
    "from utils.misc import dict_to_object, plot_specgram, plot_waveform\n",
    "from supervoice.audio import spectogram, load_mono_audio\n",
    "from supervoice.model_duration import DurationPredictor\n",
    "from supervoice.tokenizer import Tokenizer\n",
    "from train_config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08046af5-d95f-4c9c-88ee-5d693d1b752b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88145\n"
     ]
    }
   ],
   "source": [
    "# Load text grid files\n",
    "files = glob(\"datasets/vctk-aligned/**/*.TextGrid\")\n",
    "print(len(files))\n",
    "files = files[0:10]\n",
    "files = [textgrid.TextGrid.fromFile(f) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c07a148-f9d2-448d-b154-48a820c2c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "tokenizer = Tokenizer(config)\n",
    "\n",
    "# Data extractor\n",
    "def extract_data(src):\n",
    "\n",
    "    # Prepare\n",
    "    token_duration = 0.01\n",
    "    tokens = src[1]\n",
    "    time = 0\n",
    "    output_tokens = []\n",
    "    output_durations = []\n",
    "\n",
    "    # Iterate over tokens\n",
    "    for t in tokens:\n",
    "\n",
    "        # Resolve durations\n",
    "        ends = t.maxTime\n",
    "        duration = math.floor((ends - time) / token_duration)\n",
    "        time = ends\n",
    "\n",
    "        # Resolve token\n",
    "        tok = t.mark\n",
    "        if tok == '':\n",
    "            tok = tokenizer.silence_token\n",
    "\n",
    "        # Apply\n",
    "        output_tokens.append(tok)\n",
    "        output_durations.append(duration)\n",
    "\n",
    "    # Trim start silence\n",
    "    while(output_tokens[0] == 'SIL'):\n",
    "        output_durations\n",
    "    if output_tokens[0] == 'SIL' and output_durations[0] > 1:\n",
    "        output_durations[0] = 1\n",
    "    if output_tokens[len(output_tokens) - 1] == 'SIL' and output_durations[len(output_durations) - 1] > 1:\n",
    "        output_durations[len(output_durations) - 1] = 1\n",
    "\n",
    "    # Outputs\n",
    "    return output_tokens, output_durations\n",
    "    \n",
    "class TextGridDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, files):\n",
    "        self.files = files\n",
    "    def __len__(self):\n",
    "        return len(self.files)        \n",
    "    def __getitem__(self, index):\n",
    "        tg = self.files[index]\n",
    "\n",
    "        # Load tokens/durations\n",
    "        tokens, durations = extract_data(tg)\n",
    "        tokens = tokenizer(tokens)\n",
    "        durations = torch.Tensor(durations)\n",
    "\n",
    "        # Calculate mask        \n",
    "        mask_len = random.uniform(0.3, 0.7)\n",
    "        mask_offset = random.uniform(0, 1 - mask_len)\n",
    "        mask = torch.zeros(len(durations))\n",
    "        mask_start = math.floor(mask_offset * len(durations))\n",
    "        mask_end = math.floor((mask_offset + mask_len) * len(durations))\n",
    "        mask[mask_start : mask_end] = 1\n",
    "        mask = mask.bool()\n",
    "\n",
    "        # Result\n",
    "        return tokens, durations, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5e7a5b4-f033-4ed8-a0e5-c15052d002c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Dataset, model, optimizer\n",
    "device = \"cpu\"\n",
    "dataset = TextGridDataset(files)\n",
    "dataloader = DataLoader(dataset, batch_size = 1)\n",
    "model = DurationPredictor(config)\n",
    "model = model.to(device)\n",
    "optim = torch.optim.AdamW(model.parameters(), 0.0002, betas=[0.8, 0.99])\n",
    "\n",
    "checkpoint = torch.load(f'./output/duration_pre.pt', map_location=\"cpu\")\n",
    "model.load_state_dict(checkpoint['model'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d37ab71-8350-4499-8f89-e0dd4180c291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.09282242506742477\n",
      "   <SIL>      d̪      ej       m       ɐ       s       t       p       l      ej       f       ɒ       ɹ       i      tʃ       ɐ       ð       ɚ   <SIL>\n",
      "       0       5       9       7       5       9       4       6       4      10      12       5       6       6      14       6       6       8       0\n",
      "      90       9       4       8       6       9       5       7       5      10      13       3       5       9      12       8       8      12      29\n",
      "       0       0       0       0       0       0       0       0       0       1       1       1       1       1       1       1       1       1       0\n",
      "Loss: 0.19001419842243195\n",
      "   <SIL>       w      iː       w       ə       ɫ       ɲ      iː       d       t       ə       s       t       ɐ      dʲ       i      d̪       ə       ɹ       ɪ      pʰ       ɒ       ɹ       t   <SIL>       b       ə       f       ɒ       ɹ       ɛ       ɲ       i      dʲ       ɪ       s       ɪ       ʒ       ə       n       ɪ       z      tʰ      ej       k       ə       n   <SIL>\n",
      "       0       8       6       6       4       5       6       9       3       6       5       9       5       5       4       7       7       4       4       5      10       5       5       6       0       4       3      11       4       6       5       5       5       4       4      10       4       9       4       6       6       8       9       8       8       4       7       0\n",
      "      96       5       5       3       5       6       6      10       3      10       3      10       6       7       7       6       7       7       6       4      16      10       6      22       2       6       4      12       5      10      11       4      10       8       6      10       4      12       3       6       6       9       9       9      11       6      12       6\n",
      "       0       0       0       0       0       0       0       0       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       0       0       0       0       0       0       0       0       0       0       0\n",
      "Loss: 0.1244947537779808\n",
      "   <SIL>       w      iː       h       æ       v      tʰ       ʊ       c       ɹ      iː      ej       t       ə       k       l      aj      mʲ       ɪ       t       ə       v       t       ɹ       ɐ       s       t       w       ɪ      tʃ       ɪ       z       n       ɑ       t      iː       z       i\n",
      "       0       7       8       9       6       6       8       4       8       4       6       8       6       4       8       4       9       6       4       7       4       5       8       3       4       9       5       5       4       9       5       9       6       9       6       8       9       7\n",
      "      91       4       6      10       5       9       8       3      12       5       7       8      10       3      16       2      14       8       8       8       6       8      14       4      12      14       8       6       4      10       2       9       7      10      11      14      10       9\n",
      "       0       0       0       0       0       0       0       0       0       0       0       0       0       1       1       1       1       1       1       1       1       1       1       1       1       1       0       0       0       0       0       0       0       0       0       0       0       0\n",
      "Loss: 0.08149698376655579\n",
      "   <SIL>      bʲ       i       f       ɒ       ɹ      d̪       ə       ɟ      ej       m       w      iː       w       ɛ       n       t       f       ɚ       ə      pʰ      aj       n       t   <SIL>\n",
      "       0       5       4      12       4       5       5       4       7      11       7       6       6       7       5       6       4       7       3       5      11      12       5       4       0\n",
      "      89       5       5      12       5       7       5       6       7      15       6       5       6       9       7       6       4      13       2      10      14      12       6      25      25\n",
      "       0       0       0       0       0       0       0       0       0       0       0       0       0       0       1       1       1       1       1       1       1       1       0       0       0\n",
      "Loss: 0.14568662643432617\n",
      "   <SIL>       ɪ       ʔ       ɪ       z       n       ɑ       ʔ       l       ɒ       ŋ      tʰ       ɝ       m   <SIL>       b       ɐ       ʔ      aj       ɲ      iː       d      tʰ      aj       m       t       ə       ɹ       ɪ      kʰ       ɐ       v       ɚ   <SIL>\n",
      "       0       7       6       6       8       7       9       7       5       7       8      10      10       9       0       4       4       7      10       5       9       4      10      10       6       6       3       4       5      11       6       6       9       0\n",
      "      91       9      10       2       7       3       7       5       6       8      10      10      15      16      18       5       5      10       6       8      10       4      10      10       6      10       4       4       5      11       8       8      22      18\n",
      "       0       0       0       0       0       0       0       0       0       0       0       0       0       1       1       1       1       1       1       1       1       1       1       1       1       0       0       0       0       0       0       0       0       0\n",
      "Loss: 0.031450510025024414\n",
      "   <SIL>      aj       ɡ       ɑ       t       ə       j       ɛ       l      ow      kʰ       ɑ       ɹ       d\n",
      "       0      12       7       8       6       4       8       5       6       6      12       5       7       2\n",
      "      93      13      10       7      12       3       8       7       6       8      13      14      13      28\n",
      "       0       0       0       0       0       0       1       1       1       1       1       0       0       0\n",
      "Loss: 0.08115486800670624\n",
      "   <SIL>       ɪ       z      d̪       æ       ʔ       ɹ      aj       ʔ   <SIL>\n",
      "       0       6       9       5       9       7       6      13       7       0\n",
      "      74       9       9       4       8       6       7      16      21      38\n",
      "       0       0       0       1       1       1       1       1       0       0\n",
      "Loss: 0.25362110137939453\n",
      "   <SIL>       f       ɒ       ɹ       w       ɐ       n       v       ɛ       t       ə       ɹ       ə       n   <SIL>      d̪       ə       m       ɛ       m       ə       ɹ       i       z       ɹ       ɪ       m      ej       n      vʲ       ɪ      vʲ       ɪ       d   <SIL>\n",
      "       0      12       4       6       5       5       7       5       6       8       3       3       4       6       0       4       4       6       6       6       3       4       6       9       5       4       6      10       5       4       5       7       9       2       0\n",
      "      66      17       3       6       8      10      11       6       8      15       4       5       5      18      11       3       5       8      10       6       6       6      10      14       4       5       7      14      10      10       8       8      10       2     112\n",
      "       0       0       0       0       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       0       0       0       0       0       0       0\n",
      "Loss: 0.05842892453074455\n",
      "   <SIL>       j      ʉː       ʃ       ʊ       ɾ      bʲ       i   <SIL>\n",
      "       0      10       6      13       3       5       4       6       0\n",
      "      77      15       5      14       5       5      11      24      17\n",
      "       0       1       1       1       0       0       0       0       0\n",
      "Loss: 0.14947016537189484\n",
      "   <SIL>       ɪ       ʔ       ɪ       z       n       ɑ       ʔ       l      aj       k       ɐ       s   <SIL>\n",
      "       0       7       6       6       8       7      10       7       4       9       9       6      11       0\n",
      "      92      12       9       4       9       3       7       4       7      11      10      13      30      29\n",
      "       0       0       0       0       0       0       0       0       1       1       1       1       1       0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    # Predict\n",
    "    tokens, durations, mask = dataset[i]\n",
    "    predicted, loss = model(\n",
    "        tokens = tokens.unsqueeze(0).to(device), \n",
    "        durations = durations.unsqueeze(0).to(device), \n",
    "        mask = mask.unsqueeze(0).to(device), \n",
    "        target = durations.unsqueeze(0).to(device)\n",
    "    )\n",
    "    predicted = predicted.squeeze()\n",
    "\n",
    "    # Log\n",
    "    print(f'Loss: {loss.item()}')\n",
    "    print(''.join(f\"{tokenizer.tokens[num]:>8}\" for num in tokens.tolist()))\n",
    "    print(''.join(f\"{num:8}\" for num in predicted.tolist()))\n",
    "    print(''.join(f\"{int(num):8}\" for num in durations.tolist()))\n",
    "    print(''.join(f\"{int(num):8}\" for num in mask.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895fbc3e-ef49-4467-a77b-613919d6d06f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
