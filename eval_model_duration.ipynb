{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97f69095-f2ce-4966-9544-04964e19eaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base\n",
    "import itertools\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import textgrid\n",
    "import random\n",
    "\n",
    "# ML\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DistributedSampler, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Local\n",
    "from utils.misc import dict_to_object, plot_specgram, plot_waveform\n",
    "from supervoice.audio import spectogram, load_mono_audio\n",
    "from supervoice.model_duration import DurationPredictor\n",
    "from supervoice.tokenizer import Tokenizer\n",
    "from train_config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08046af5-d95f-4c9c-88ee-5d693d1b752b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88141\n"
     ]
    }
   ],
   "source": [
    "# Load text grid files\n",
    "files = glob(\"datasets/vctk-aligned/**/*.TextGrid\")\n",
    "print(len(files))\n",
    "files = files[0:10]\n",
    "files = [textgrid.TextGrid.fromFile(f) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c07a148-f9d2-448d-b154-48a820c2c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "tokenizer = Tokenizer(config)\n",
    "\n",
    "# Data extractor\n",
    "def extract_data(src):\n",
    "\n",
    "    # Prepare\n",
    "    token_duration = 0.01\n",
    "    tokens = src[1]\n",
    "    time = 0\n",
    "    output_tokens = []\n",
    "    output_durations = []\n",
    "\n",
    "    # Iterate over tokens\n",
    "    for t in tokens:\n",
    "\n",
    "        # Resolve durations\n",
    "        ends = t.maxTime\n",
    "        duration = math.floor((ends - time) / token_duration)\n",
    "        time = ends\n",
    "\n",
    "        # Resolve token\n",
    "        tok = t.mark\n",
    "        if tok == '':\n",
    "            tok = tokenizer.silence_token\n",
    "\n",
    "        # Apply\n",
    "        output_tokens.append(tok)\n",
    "        output_durations.append(duration)\n",
    "\n",
    "    # Trim start silence\n",
    "    if output_tokens[0] == 'SIL' and output_durations[0] > 1:\n",
    "        output_durations[0] = 1\n",
    "    if output_tokens[len(output_tokens) - 1] == 'SIL' and output_durations[len(output_durations) - 1] > 1:\n",
    "        output_durations[len(output_durations) - 1] = 1\n",
    "\n",
    "    # Outputs\n",
    "    return output_tokens, output_durations\n",
    "    \n",
    "class TextGridDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, files):\n",
    "        self.files = files\n",
    "    def __len__(self):\n",
    "        return len(self.files)        \n",
    "    def __getitem__(self, index):\n",
    "        tg = self.files[index]\n",
    "\n",
    "        # Load tokens/durations\n",
    "        tokens, durations = extract_data(tg)\n",
    "        tokens = tokenizer(tokens)\n",
    "        durations = torch.Tensor(durations)\n",
    "\n",
    "        # Calculate mask        \n",
    "        mask_len = random.uniform(0.3, 0.7)\n",
    "        mask_offset = random.uniform(0, 1 - mask_len)\n",
    "        mask = torch.zeros(len(durations))\n",
    "        mask_start = math.floor(mask_offset * len(durations))\n",
    "        mask_end = math.floor((mask_offset + mask_len) * len(durations))\n",
    "        mask[mask_start : mask_end] = 1\n",
    "        mask = mask.bool()\n",
    "\n",
    "        # Result\n",
    "        return tokens, durations, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5e7a5b4-f033-4ed8-a0e5-c15052d002c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Dataset, model, optimizer\n",
    "device = \"cpu\"\n",
    "dataset = TextGridDataset(files)\n",
    "dataloader = DataLoader(dataset, batch_size = 1)\n",
    "model = DurationPredictor(config)\n",
    "model = model.to(device)\n",
    "optim = torch.optim.AdamW(model.parameters(), 0.0002, betas=[0.8, 0.99])\n",
    "\n",
    "checkpoint = torch.load(f'./checkpoints/duration_pre.pt', map_location=\"cpu\")\n",
    "model.load_state_dict(checkpoint['model'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d37ab71-8350-4499-8f89-e0dd4180c291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.06103821098804474\n",
      "   <SIL>      mʲ       ɪ       s       t       ɚ       æ       n       d       ɚ       s       ə       n       w       ə       z       n       ɑ       t       æ       k      tʲ       ɪ       ŋ       ɪ       n      d̪       ə      kʰ       ɒ       ɹ       s       ə       v       ç       ɪ       z       ɪ       m       p       l      ɔj       m       ɛ       n       t   <SIL>\n",
      "       7       6       4       7       6       5       9       6       1       5      11       3       5       3       4       7       4       6       6       7       6       5       4       6       5       4       3       3      11       6       6       9       4       4       5       5       6       4       5       7       3      12       6       7       5       8       6\n",
      "       3       5       5       7       3      10       7       6       2       4       9       4       7       3       3       6       4       7       9      10       5       6       5       3       5       5       3       3       9       3       8       9       3       3       3       3       6       6       8       6       4      12       4       5       6      16       4\n",
      "       0       0       0       0       0       0       0       0       0       0       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0\n",
      "Loss: 0.13108879327774048\n",
      "       w      iː       ɛ       ɹ       ɑ       n       ə       f       ɒ       ɹ       j       ɪ       ɹ      mʲ       ɪ       ʃ       ə       n\n",
      "       5       8       5       6       7       4       4      11       5       5       6       5       5       6       5      11       3       5\n",
      "       8       9       3       7       7       6       3      13       9       6       9       6       6       7       6      10       6      14\n",
      "       0       1       1       1       1       1       1       1       1       1       1       1       0       0       0       0       0       0\n",
      "Loss: 0.13934282958507538\n",
      "   <SIL>       ç      iː       k       l      ej       m       d       ç       ɪ       z       ɪ       n       ʃ       ʊ       ɹ       ə       n       s      kʰ       ɐ       m       p       ə       ɲ       i      kʰ       ə       n      tʰ       ɛ       s      tʲ       ɪ       d      d̪       ə       d       æ      mʲ       ɪ      dʒ       ɪ       z   <SIL>       n       ɑ       ʔ      d̪       ə       ɹ       ɛ       s       t       ə       ɹ       ɑ       n       t   <SIL>\n",
      "       7       7       5       7       4      11       6       2       6       4       6       4       4      10       3       4       3       4       9       8       5       5       5       3       3       6       8       3       5       7       6       9       5       4       2       4       3       5       9       7       5       8       8      14       6       6       6       4       4       3       6       6       8       5       3       6       9       6       9       6\n",
      "       3       7       3      13       3      10       7       2       6       3      10       3       3      12       3       3       5       3       7       5       4       4       7       4       4       6       9       3       3       9       8       8       5       6       2       4       4       8      10       6       6       6      12      19      27      11       4       6       3       4       4       7       8       6       3       2       4       6      12       5\n",
      "       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       0       0       0       0\n",
      "Loss: 0.2811373770236969\n",
      "      d̪      ej       ɑ       ɹ       ɹ       ɒ       ŋ\n",
      "       4       9       7       6       6       9       7\n",
      "       7      12       4       5      13      15      20\n",
      "       0       1       1       1       1       1       0\n",
      "Loss: 0.18100792169570923\n",
      "       ɪ       ʔ       w       ə       ɫ      dʲ       ɪ       s      aj       ɾ      tʰ       ə       d      ej       w       ɛ      d̪       ɚ       ç      iː       ʃ       ʊ       d      bʲ       i       s       t       ɹ       ɐ       k       ɒ       f      d̪       ə       ɹ       ɛ      dʒ       ɪ       s       t       ɚ   <SIL>\n",
      "       5       4       4       3       4       5       3      10      11       4       8       3       4       9       6       6       4       5       8       6      12       5       2       5       5       9       6       4       4       8       8       8       3       3       6       6       8       4       8       6      11       7\n",
      "       9       8       4       3       3       9       4       8      10       4       5       3      10      18       8       7       4       7       6       3      12       3       2       5       5       4       9       3       2       9       5       9       4       5       2       8      10       2       4       7      16       4\n",
      "       0       0       0       0       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       0       0       0       0       0       0       0       0       0       0       0       0\n",
      "Loss: 0.10186609625816345\n",
      "   <SIL>      aj       æ       m       ə       w       ɛ       ɫ       θ       i      pʰ       ɝ       s       ə       n   <SIL>\n",
      "       6      13       8       4       3       6       5       6       7       5      10       8      11       5       9       8\n",
      "       3      11       6       7       3       9       6       6      10       4       9      12      10       3      11       6\n",
      "       0       0       0       0       0       0       0       0       1       1       1       1       1       1       0       0\n",
      "Loss: 0.11633282154798508\n",
      "      aj       v      pʰ       ʊ       t       m      aj      ow       n       m       ɐ       ɲ       i       ɪ       n      tʰ       ʉ      d̪       ɪ       s       p       ɹ       ɑ      dʒ       ɛ       k       t   <SIL>\n",
      "      11       6       7       4       4       5      11      11       6       4       5       4       8       5       4       7       4       5       4       8       6       4       7       9       8       8       8       6\n",
      "      12       9       7       6       7       3       8      10       4       6       7       4       6       7       5       7       3       5       4       9       5       4       7      10       9       7      14       6\n",
      "       0       0       0       0       0       0       0       0       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       0\n",
      "Loss: 0.1590411216020584\n",
      "       æ      d̪       ə      tʰ      aj       m   <SIL>       ç      iː       w       ə       z       ə       ʎ       ɪ      vʲ       ɪ       ŋ       l       ɛ      dʒ       ə       n       d   <SIL>\n",
      "       6       4       3      10      15      11       9       8       4       4       3       6       3       6       4       4       4       6       5       7       7       5       8       2       7\n",
      "       9       7       6       9      16      15      18       9       3       5       5       4       6       9       5       4       6       7       5       8       8       5      12       2      13\n",
      "       0       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       0       0       0       0       0       0       0       0       0\n",
      "Loss: 0.1435510218143463\n",
      "       ɪ       ʔ       w       ɐ       z       ə       n       t       ə      pʰ       ɛ       n       ə       ɫ      tʲ       i   <SIL>       ɪ       w       ə       z      aw       t       s      aj       d      d̪      iː       ɛ       ɹ       i       ə   <SIL>\n",
      "       5       4       4       5       7       4       4       4       3      10       6       4       4       3       9      15       8       7       4       4       7      12       4       8      10       2       5       6       6       7       9      10       7\n",
      "      10       6       6       7       4       3       2       4       3       7       6       4       4       3       7      15      30       9       4       3       7      10       4       6      10       2       5       9       4       5       8      18       4\n",
      "       0       0       0       0       0       0       0       0       0       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       1       0       0\n",
      "Loss: 0.1337563842535019\n",
      "       ɒ       f       w       ɪ       θ      d̪       ɛ       ɹ       h       ɛ       d       z   <SIL>\n",
      "      10      10       3       4       4       4       5       4       7       9       3      14       7\n",
      "      12      12       3       3       6       4       4       4       5      13       4      21       4\n",
      "       0       0       0       0       1       1       1       1       1       1       1       1       0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    # Predict\n",
    "    tokens, durations, mask = dataset[i]\n",
    "    predicted, loss = model(\n",
    "        tokens = tokens.unsqueeze(0).to(device), \n",
    "        durations = durations.unsqueeze(0).to(device), \n",
    "        mask = mask.unsqueeze(0).to(device), \n",
    "        target = durations.unsqueeze(0).to(device)\n",
    "    )\n",
    "    predicted = predicted.squeeze()\n",
    "\n",
    "    # Log\n",
    "    print(f'Loss: {loss.item()}')\n",
    "    print(''.join(f\"{tokenizer.tokens[num]:>8}\" for num in tokens.tolist()))\n",
    "    print(''.join(f\"{num:8}\" for num in predicted.tolist()))\n",
    "    print(''.join(f\"{int(num):8}\" for num in durations.tolist()))\n",
    "    print(''.join(f\"{int(num):8}\" for num in mask.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895fbc3e-ef49-4467-a77b-613919d6d06f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
